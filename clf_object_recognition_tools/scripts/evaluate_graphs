#!/usr/bin/env python

import sys
import rospy
from clf_object_recognition_tools import evaluation

if __name__ == "__main__":

    rospy.init_node('clf_object_evaluation_node')

    try:
        test_dir = rospy.get_param("~test_dir")
        logging_dir = rospy.get_param("~logging_dir")
        mode = rospy.get_param("~mode", 0)
        threshold = rospy.get_param("~threshold", 0.5)
        visualize = rospy.get_param("~visualize", False)
    except KeyError as e:
        print("Parameter %s not found" % e)
        sys.exit(1)

    # check valid mode
    if mode < 0 or mode > 3:
        print("ERROR: Mode {} does not exist. Select one of the following modes:"
              "\n0 - evaluate detection bounding boxes (ignore labels)"
              "\n1 - evaluate detection (boxes + labels)"
              "\n2 - evaluate detection with re-labeling"
              "\n3 - evaluate recognition based on predefined images".format(mode))
        exit(1)

    if mode < 2:
        try:
            detection_graph_dir = rospy.get_param("~detection_graphs")
            label_map_file = rospy.get_param("~detection_labels")
        except KeyError as e:
            print("Parameter %s not found" % e)
            sys.exit(1)

    else:
        detection_graph_dir = ""
        label_map_file = ""

    if mode > 1:
        try:
            recognition_graph_dir = rospy.get_param("~recognition_graphs")
            recognition_labels = rospy.get_param("~recognition_labels")
        except KeyError as e:
            print("Parameter %s not found" % e)
            sys.exit(1)
    else:
        recognition_graph_dir = ""
        recognition_labels = ""

    # try to read graphs and label files, then check if all required are accessible
    detection_graphs, label_map_dict = evaluation.get_detection_graphs_and_labels(detection_graph_dir, label_map_file)
    recognition_graphs, labels_dict = evaluation.get_recognition_graphs_and_labels(recognition_graph_dir, recognition_labels)

    print("label map dict:")
    print(label_map_dict)

    print("label file dict:")
    print(labels_dict)

    if mode <= 2 and (not detection_graphs or label_map_dict is None):
        print("ERROR: Couldn't read detection graphs or label map.")
        exit(0)

    # get image list (either whole images or rois)
    image_list = []
    test_labels_dict = None
    if mode < 3:
        if mode < 2:
            image_list, test_labels_dict = evaluation.read_test_dir(test_dir, "/images", 1)
        else:
            image_list, test_labels_dict = evaluation.read_test_dir(test_dir, "/images", 0)
    else:
        image_list, test_labels_dict = evaluation.read_test_dir(test_dir, "/rois", 0)    # mode 3

    if not image_list:
        print("ERROR: Couldn't find any valid images at "+test_dir)
        exit(0)

    if not test_labels_dict:
        print("ERROR: File does not exist or is empty: " + test_dir + "labels.txt")
        exit(0)

    print(test_labels_dict)

    if mode == 1:
        if test_labels_dict == label_map_dict:
            print("Label dictionaries match")
        else:
            print("Testset and trained graph cannot be compared, because they have different label dictionaries.")
            print("test: "+str(test_labels_dict))
            print("graph: "+str(label_map_dict))
            exit(0)

    if mode == 2:
        if len(test_labels_dict) == len(labels_dict):
            print("Label dictionaries match")
        else:
            # todo: merge somehow (ids of the graph as reference!)
            print("Testset and trained graph cannot be compared, because they have different label dictionaries.")
            print("test: "+str(test_labels_dict))
            print("graph: "+str(labels_dict))
            exit(0)

    # set threshold (default if argument is invalid)
    min_threshold = 0.2
    if threshold < 0 or threshold > 1:
        threshold = 0.5
    else:
        min_threshold = threshold

    # call evaluation according to selected mode
    if mode == 0:
        evaluation.evaluate_detection(image_list, test_labels_dict, detection_graphs, label_map_file, min_threshold=min_threshold,
                           ignore_labels=True, do_recognition=False, graph_r=None, labels_r=None,
                           save_images=visualize, logging_dir=logging_dir)
    elif mode == 1:
        evaluation.evaluate_detection(image_list, test_labels_dict, detection_graphs, label_map_file, min_threshold=min_threshold,
                           ignore_labels=False, do_recognition=False, graph_r=None, labels_r=None,
                           save_images=visualize, logging_dir=logging_dir)
    elif mode == 2:
        evaluation.evaluate_detection(image_list, test_labels_dict, detection_graphs, label_map_file, min_threshold=min_threshold,
                           ignore_labels=True, do_recognition=True, graph_r=recognition_graphs[0],
                           labels_r=recognition_labels, save_images=visualize, logging_dir=logging_dir)
    elif mode == 3:
        evaluation.evaluate_recognition(image_list, test_labels_dict, labels_dict, recognition_graphs, recognition_labels)

    print("Done")